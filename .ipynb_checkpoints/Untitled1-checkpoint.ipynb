{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ca9acb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (130224553.py, line 46)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    workspace=config.COMET_WORKSPACE,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import ConfusionMatrix, Experiment\n",
    "\n",
    "import os\n",
    "import multiprocessing\n",
    "import time\n",
    "from collections import Counter, OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import MaxPooling2D, Conv2D\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.models import load_model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from loguru import logger\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import constants\n",
    "\n",
    "import config\n",
    "\n",
    "# To use Comet ML visualization and logging you have to follow the instructions from README.md\n",
    "# on how to set COMET_API_KEY, COMET_WORKSPACE, COMET_PROJECT_NAME environment variables\n",
    "# Alternatively, you can set these variables manually in the code here by uncommenting the lines below\n",
    "# os.environ[\"COMET_API_KEY\"] = 'YOUR_API_KEY'\n",
    "# os.environ[\"COMET_WORKSPACE\"] = 'YOUR_WORKSPACE'\n",
    "# os.environ[\"COMET_PROJECT_NAME\"] = 'YOUR_PROJECT_NAME'\n",
    "\n",
    "USE_COMET_ML = config.COMET_API_KEY and config.COMET_WORKSPACE \\\n",
    "            and config.COMET_PROJECT_NAME\n",
    "\n",
    "if USE_COMET_ML:\n",
    "    experiment = Experiment(\n",
    "        api_key=config.COMET_API_KEY,\n",
    "        workspace=config.COMET_WORKSPACE,\n",
    "        project_name=config.COMET_PROJECT_NAME\n",
    "    )\n",
    "\n",
    "\"\"\"Parameters to adjust\"\"\"\n",
    "LANG_SET = 'en_sp_64mel_'  # what languages to use / fr_it_sp\n",
    "FEATURES = 'fbe'  # mfcc / f0 / cen / rol / chroma / rms / zcr / fbe [Feature types] mfcc_f0_cen_rol_chroma_rms_zcr\n",
    "MAX_PER_LANG = 80  # maximum number of audios of a language\n",
    "\n",
    "UNSILENCE = False\n",
    "\n",
    "WIN_LENGTH_MS = 25  # ms / 25\n",
    "OVERLAP_MS = 10  # ms / 10\n",
    "\n",
    "SAMPLE_RATE = 22050  # 22050 / 16000 [Hz]\n",
    "HOP_LENGTH = int(SAMPLE_RATE * 0.001 * OVERLAP_MS)  # [10 ms overlap]\n",
    "WIN_LENGTH = int(SAMPLE_RATE * 0.001 * WIN_LENGTH_MS)  # [25 ms window length]\n",
    "# N_FFT = int(SAMPLE_RATE * 0.001 * WIN_LENGTH)  # [25 ms window length]\n",
    "FRAME_SIZE = 75  # 30 / 50 / 70 / 100 / 150 / 200 / 300 / 500 [Size of feature segment]\n",
    "\n",
    "MEL_S_LOG = False\n",
    "\n",
    "selection_method = 'UNIVARIATE'  # PCE / UNIVARIATE\n",
    "SCORE_FUNC = f_classif  # f_classif / mutual_info_classif [score function for univariate  feature selector]\n",
    "NUM_OF_FEATURES = 10  # [number of optimal features to work with]\n",
    "SELECT_FEATURES = False  # [whether to use feature selection method]\n",
    "CHECK_DATASETS = True\n",
    "\n",
    "EPOCHS = 60  # [Number of training epochs]\n",
    "BATCH_SIZE = 64  # size of mini-batch used\n",
    "KERNEL_SIZE = (3, 3)  # (3, 3) (5, 5)\n",
    "POOL_SIZE = (3, 3)  # (2, 2) (3, 3)\n",
    "DROPOUT = 0.1  # 0.5 for mfcc CNN\n",
    "BASELINE = 1.0\n",
    "MIN_DELTA = .01  # .01\n",
    "PATIENCE = 10  # 10\n",
    "N_MELS = 64  # [number of filters for a mel-spectrogram]\n",
    "\n",
    "\n",
    "def filter_df(df):\n",
    "    \"\"\"\n",
    "    Filters audio files DataFrame based on options:\n",
    "    [language, path -- path to file, path_unsilenced -- path to file with removed silence parts].\n",
    "    Dictionary of available languages is defined in constants.py.\n",
    "    :param df: (DataFrame) unfiltered audio files DataFrame\n",
    "    :return: (DataFrame) filtered DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    lang_codes = [lc for lc in LANG_SET.split('_') if lc in constants.LANGUAGES]\n",
    "    df_to_include = []\n",
    "    for lang_code in lang_codes:\n",
    "        lang_fullname = constants.LANGUAGES[lang_code]\n",
    "        # TODO: Filter recordings randomly (based on random seed), not first ones\n",
    "        df_to_include.append(df[df.language == lang_fullname][:MAX_PER_LANG])\n",
    "    return pd.concat(df_to_include)\n",
    "\n",
    "\n",
    "def extract_features(audio_file):\n",
    "    \"\"\"\n",
    "    Extracts features from audio files.\n",
    "    Different kinds of features are concatenated subsequently.\n",
    "    :param audio_file: (String) path to a .wav audio file\n",
    "    :return: (numpy.ndarray) feature matrices\n",
    "    (columns == FRAME_SIZE, rows == number of features)\n",
    "    \"\"\"\n",
    "    if not Path(audio_file).exists():\n",
    "        logger.warning(f\"Audio file {audio_file} is not found. Check the dataset\")\n",
    "        return\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "    y = librosa.core.resample(y=y, orig_sr=sr, target_sr=SAMPLE_RATE, scale=True)\n",
    "    s, _ = librosa.magphase(librosa.stft(y, hop_length=HOP_LENGTH, win_length=WIN_LENGTH))  # magnitudes of spectrogram\n",
    "    features = []\n",
    "    if 'mfcc' in FEATURES:\n",
    "        mfccs = derive_mfcc(audio_file, y)\n",
    "        features.append(mfccs)\n",
    "    if 'f0' in FEATURES:\n",
    "        f0 = derive_f0(audio_file, y)\n",
    "        features.append(f0)\n",
    "    if 'cen' in FEATURES:\n",
    "        spectral_centroid = derive_spectral_centroid(audio_file, y)\n",
    "        features.append(spectral_centroid)\n",
    "    if 'rol' in FEATURES:\n",
    "        spectral_rolloff = derive_spectral_rolloff(audio_file, y)\n",
    "        features.append(spectral_rolloff)\n",
    "    if 'chroma' in FEATURES:\n",
    "        chromagram = derive_chromagram(audio_file, y)\n",
    "        features.append(chromagram)\n",
    "    if 'rms' in FEATURES:\n",
    "        rms = derive_rms(audio_file, s)\n",
    "        features.append(rms)\n",
    "    if 'zcr' in FEATURES:\n",
    "        zcr = derive_zcr(audio_file, y)\n",
    "        features.append(zcr)\n",
    "    if 'fbe' in FEATURES:\n",
    "        mel_s = derive_mel_s(audio_file, y)\n",
    "        features.append(mel_s)\n",
    "\n",
    "    logger.debug('Concatenating extracted features...')\n",
    "    features = np.vstack(features)\n",
    "    logger.debug(f'Shape of concatenated features: {features.shape}')\n",
    "    return features\n",
    "\n",
    "\n",
    "def normalize_feature_vectors(feature_vectors):\n",
    "    \"\"\"\n",
    "    Normalizes features presented by a vector (e.g. Mel-Cepstral coefficients, Mel-spectrogram).\n",
    "    One vector corresponds to an audio segment of WIN_LENGTH length.\n",
    "    :param feature_vectors: (numpy.ndarray) Vectors of features extracted from an audio file.\n",
    "    :return: (numpy.ndarray) List of normalized vectors of features\n",
    "    \"\"\"\n",
    "    mean = np.mean(feature_vectors.T, axis=0, dtype=np.float64)\n",
    "    std = np.std(feature_vectors, dtype=np.float64)\n",
    "    feature_vectors_normalized = []\n",
    "    for i in range(feature_vectors.shape[1]):\n",
    "        feature_vectors_normalized.append(np.subtract(feature_vectors[:, i], mean) / std)\n",
    "    feature_vectors_normalized = np.array(feature_vectors_normalized)\n",
    "    return feature_vectors_normalized.T\n",
    "\n",
    "\n",
    "def normalize_scalar_feature(feature_vector):\n",
    "    \"\"\"\n",
    "    Normalizes scalar features (e.g. spectral roll-off, F0, etc.).\n",
    "    Each feature is extracted from an audio segment of WIN_LENGTH length.\n",
    "    :param feature_vector: (numpy.ndarray) Vector of scalar features\n",
    "    :return: (numpy.ndarray) List of normalized features\n",
    "    \"\"\"\n",
    "    mean = np.mean(feature_vector, dtype=np.float64)\n",
    "    std = np.std(feature_vector, dtype=np.float64)\n",
    "    feature_vector_normalized = (feature_vector - mean) / std\n",
    "    return feature_vector_normalized\n",
    "\n",
    "\n",
    "def derive_mfcc(audio_file, y):\n",
    "    \"\"\"\n",
    "    Derives Mel-Cepstral coefficients from each frame of an audio file.\n",
    "    Coefficients are normalized for each audio file to deal with\n",
    "    the difference in volume and background noise.\n",
    "    :param audio_file: (String) Relative audio file name\n",
    "    :param y: (numpy.ndarray) Loaded and resampled at SAMPLE_RATE audio file\n",
    "    :return: (numpy.ndarray) Vectors of normalized MFCC\n",
    "    \"\"\"\n",
    "    logger.debug(f'Extracting MFCC for {audio_file}...')\n",
    "    '''if 'energy' in LANG_SET:\n",
    "        mfcc = python_speech_features.mfcc(signal=y, samplerate=SAMPLE_RATE, winlen=WIN_LENGTH / SAMPLE_RATE,\n",
    "                                           winstep=HOP_LENGTH / SAMPLE_RATE, appendEnergy=True, numcep=14,\n",
    "                                           winfunc=hann, preemph=0.0, ceplifter=0, nfilt=128, lowfreq=0,\n",
    "                                           highfreq=None, nfft=2048).T\n",
    "    if 'log' in LANG_SET:\n",
    "        mel_s = librosa.feature.melspectrogram(y=y, sr=SAMPLE_RATE, n_mels=N_MELS, hop_length=HOP_LENGTH,\n",
    "                                               win_length=WIN_LENGTH, power=2.0)\n",
    "        mfcc = librosa.feature.mfcc(S=librosa.power_to_db(mel_s), n_mfcc=13, hop_length=HOP_LENGTH,\n",
    "                                    win_length=WIN_LENGTH)\n",
    "                                    \n",
    "    else: '''\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=SAMPLE_RATE, n_mfcc=13, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)\n",
    "    mfcc_normalized = normalize_feature_vectors(mfcc)\n",
    "    return mfcc_normalized\n",
    "\n",
    "\n",
    "def derive_mel_s(audio_file, y):\n",
    "    \"\"\"\n",
    "    Derives Mel-Spectrogram of amplitude from each frame of an audio file.\n",
    "    Coefficients are normalized for each audio file to deal with\n",
    "    the difference in volume and background noise.\n",
    "    :param audio_file: (String) Relative audio file name\n",
    "    :param y: (numpy.ndarray) Loaded and resampled at SAMPLE_RATE audio file\n",
    "    :return: (numpy.ndarray) Vectors of normalized mel-spectrograms\n",
    "    \"\"\"\n",
    "    logger.debug(f'Extracting Mel-spectrogram for {audio_file}...')\n",
    "    mel_s = librosa.feature.melspectrogram(y=y, sr=SAMPLE_RATE, n_mels=N_MELS, hop_length=HOP_LENGTH,\n",
    "                                           win_length=WIN_LENGTH, power=1.0)\n",
    "    if MEL_S_LOG:\n",
    "        mel_s = librosa.power_to_db(mel_s)\n",
    "    mel_s_normalized = normalize_feature_vectors(mel_s)\n",
    "    return mel_s_normalized\n",
    "\n",
    "\n",
    "def derive_f0(audio_file, y):\n",
    "    \"\"\"\n",
    "    Derives fundamental frequencies from each frame of an audio file.\n",
    "    Coefficients are normalized for each audio file to deal with\n",
    "    the difference in volume and background noise.\n",
    "    :param audio_file: (String) Relative audio file name\n",
    "    :param y: (numpy.ndarray) Loaded and resampled at SAMPLE_RATE audio file\n",
    "    :return: (numpy.ndarray) Vector of normalized fundamental frequencies\n",
    "    \"\"\"\n",
    "    logger.debug(f'Extracting fundamental frequency for {audio_file}...')\n",
    "    f0 = librosa.yin(y, librosa.note_to_hz('C2'), librosa.note_to_hz('C7'), sr=SAMPLE_RATE, hop_length=HOP_LENGTH,\n",
    "                     win_length=WIN_LENGTH)\n",
    "    f0_normalized = normalize_scalar_feature(f0)\n",
    "    return f0_normalized\n",
    "\n",
    "\n",
    "def derive_spectral_centroid(audio_file, y):\n",
    "    \"\"\"\n",
    "    Derives spectral centroid from each frame of an audio file.\n",
    "    Coefficients are normalized for each audio file to deal with\n",
    "    the difference in volume and background noise.\n",
    "    :param audio_file: (String) Relative audio file name\n",
    "    :param y: (numpy.ndarray) Loaded and resampled at SAMPLE_RATE audio file\n",
    "    :return: (numpy.ndarray) Vector of normalized spectral centroids\n",
    "    \"\"\"\n",
    "    logger.debug(f'Extracting spectral centroid for {audio_file}...')\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y, sr=SAMPLE_RATE, hop_length=HOP_LENGTH,\n",
    "                                                          win_length=WIN_LENGTH)\n",
    "    spectral_centroid_normalized = normalize_scalar_feature(spectral_centroid)\n",
    "    return spectral_centroid_normalized\n",
    "\n",
    "\n",
    "def derive_spectral_rolloff(audio_file, y):\n",
    "    \"\"\"\n",
    "    Derives spectral centroid from each frame of an audio file.\n",
    "    Coefficients are normalized for each audio file to deal with\n",
    "    the difference in volume and background noise.\n",
    "    :param audio_file: (String) Relative audio file name\n",
    "    :param y: (numpy.ndarray) Loaded and resampled at SAMPLE_RATE audio file\n",
    "    :return: (numpy.ndarray) Vector of normalized spectral roll-off values\n",
    "    \"\"\"\n",
    "    logger.debug(f'Extracting spectral rolloff for {audio_file}...')\n",
    "    rolloff = librosa.feature.spectral_rolloff(y, sr=SAMPLE_RATE, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)\n",
    "    rolloff_normalized = normalize_scalar_feature(rolloff)\n",
    "    return rolloff_normalized\n",
    "\n",
    "\n",
    "def derive_chromagram(audio_file, y):\n",
    "    \"\"\"\n",
    "    Derives N chroma bins from each frame of an audio file.\n",
    "    Coefficients are normalized for each audio file to deal with\n",
    "    the difference in volume and background noise.\n",
    "    :param audio_file: (String) Relative audio file name\n",
    "    :param y: (numpy.ndarray) Loaded and resampled at SAMPLE_RATE audio file\n",
    "    :return: (numpy.ndarray) Vectors of normalized chroma bins of an audio file\n",
    "    \"\"\"\n",
    "    logger.debug(f'Extracting chromagram for {audio_file}...')\n",
    "    chromagram = librosa.feature.chroma_stft(y=y, sr=SAMPLE_RATE, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)\n",
    "    chromagram_normalized = normalize_feature_vectors(chromagram)\n",
    "    return chromagram_normalized\n",
    "\n",
    "\n",
    "def derive_rms(audio_file, s):\n",
    "    \"\"\"\n",
    "    Derives root-mean-square (RMS) value from each frame of an audio file.\n",
    "    Coefficients are normalized for each audio file to deal with\n",
    "    the difference in volume and background noise.\n",
    "    :param audio_file: (String) Relative audio file name\n",
    "    :param s: (numpy.ndarray) magnitudes (S) of a Spectrogram\n",
    "    :return: (numpy.ndarray) Vector of normalized RMS values\n",
    "    \"\"\"\n",
    "    logger.debug(f'Extracting chromagram for {audio_file}...')\n",
    "    rms = librosa.feature.rms(S=s)[0]\n",
    "    rms_normalized = normalize_scalar_feature(rms)\n",
    "    return rms_normalized\n",
    "\n",
    "\n",
    "def derive_zcr(audio_file, y):\n",
    "    \"\"\"\n",
    "    Derives zero-crossing rate from each frame of an audio file.\n",
    "    Coefficients are normalized for each audio file to deal with\n",
    "    the difference in volume and background noise.\n",
    "    :param audio_file: (String) Relative audio file name\n",
    "    :param y: (numpy.ndarray) Loaded and resampled at SAMPLE_RATE audio file\n",
    "    :return: (numpy.ndarray) Vector of normalized ZCR\n",
    "    \"\"\"\n",
    "    logger.debug(f'Extracting ZCR for {audio_file}...')\n",
    "    zcr = librosa.feature.zero_crossing_rate(y, hop_length=HOP_LENGTH, frame_length=WIN_LENGTH * 2)\n",
    "    zcr_normalized = normalize_scalar_feature(zcr)\n",
    "    return zcr_normalized\n",
    "\n",
    "\n",
    "def split_into_matrices(feature_vectors, labels):\n",
    "    \"\"\"\n",
    "    Makes segments of vectors of features\n",
    "    and attaches them to the corresponding labels.\n",
    "    :param feature_vectors: vectors of features\n",
    "    :param labels: list of labels\n",
    "    :return: (tuple) Matrices with corresponding labels\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    seg_labels = []\n",
    "    for feature_vector, label in zip(feature_vectors, labels):\n",
    "        for frame_start in range(0, int(feature_vector.shape[1] / FRAME_SIZE)):\n",
    "            segments.append(feature_vector[:, frame_start * FRAME_SIZE:(frame_start + 1) * FRAME_SIZE])\n",
    "            seg_labels.append(label)\n",
    "    return segments, seg_labels\n",
    "\n",
    "\n",
    "def create_segments_after_selection(data_arrays):\n",
    "    \"\"\"\n",
    "    Splits selected features into matrices\n",
    "    :param data_arrays:\n",
    "    :return: matrices of features\n",
    "    \"\"\"\n",
    "    segments_arrays = ()\n",
    "    for data_array in data_arrays:\n",
    "        segments = []\n",
    "        logger.debug(f'\\nShape of data before segmenting: {data_array.shape}')\n",
    "        for element in data_array:\n",
    "            segments.append(element.reshape(NUM_OF_FEATURES, FRAME_SIZE))\n",
    "        logger.debug(f'Shape of segmented data: {np.array(segments).shape}\\n')\n",
    "        segments_arrays = segments_arrays + (np.array(segments),)\n",
    "    return segments_arrays\n",
    "\n",
    "\n",
    "def preprocess_new_data(x, y):\n",
    "    \"\"\"\n",
    "    Loads .WAV files, extracts features from them and saves extracted features\n",
    "    with corresponding meta information to files for future use.\n",
    "    :param x: list of audio paths\n",
    "    :param y: corresponding languages\n",
    "    :return: (tuple) train and test sets, information about classes distribution\n",
    "    \"\"\"\n",
    "    logger.info(f'Languages distribution by audios: {Counter(y)}')\n",
    "\n",
    "    logger.debug('Transforming y to categorical...')\n",
    "    le = LabelEncoder()\n",
    "    y_categorical = to_categorical(le.fit_transform(y))\n",
    "\n",
    "    classes = get_classes_map(y_categorical, y)\n",
    "\n",
    "    logger.debug('Loading WAV files...')\n",
    "    pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "    x = pool.map(extract_features, x)\n",
    "    if any(feature is None for feature in x):\n",
    "        logger.error(\"Some audio files are missing. See the log warnings above and fix the dataset before proceeding\")\n",
    "        return None\n",
    "\n",
    "    logger.debug('Making segments of feature vectors...')\n",
    "    x_segmented, y_segmented = split_into_matrices(x, y_categorical)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_segmented, y_segmented, test_size=0.25, random_state=1234)\n",
    "\n",
    "    train_count = Counter([np.where(y == 1)[0][0] for y in y_train])\n",
    "    test_count = Counter([np.where(y == 1)[0][0] for y in y_test])\n",
    "\n",
    "    logger.debug(f'Train count: {train_count}')\n",
    "    logger.debug(f'Test count: {test_count}')\n",
    "\n",
    "    logger.debug(f'Length of training set: {len(x_train)}')\n",
    "    logger.debug(f'Length of testing set: {len(x_test)}')\n",
    "\n",
    "    assert (len(x_train) == len(y_train)) and (len(x_test) == len(y_test))\n",
    "\n",
    "    save_input_data_to_files(x_train, x_test, y_train, y_test, train_count, test_count, classes)\n",
    "\n",
    "    return np.array(x_train), np.array(x_test), np.array(y_train), np.array(y_test), \\\n",
    "           train_count, test_count, classes\n",
    "\n",
    "\n",
    "def get_classes_map(y, y_raw):\n",
    "    \"\"\"\n",
    "    :param y: binary representation of labels\n",
    "    :param y_raw: list of languages in String form\n",
    "    :return (OrderedDict): language to binary correspondence\n",
    "    \"\"\"\n",
    "    classes = {}\n",
    "    while len(classes) < len(Counter(y_raw)):\n",
    "        for raw, category in zip(y_raw, y):\n",
    "            classes[np.argmax(category)] = raw\n",
    "    ordered_classes = OrderedDict(sorted(classes.items()))\n",
    "    return ordered_classes\n",
    "\n",
    "\n",
    "def save_input_data_to_files(x_train, x_test, y_train, y_test, train_count, test_count, classes):\n",
    "    \"\"\"\n",
    "    Creates 2 files:\n",
    "    - file with training and testing sets saved\n",
    "    - file with information about classes distribution\n",
    "    :param x_train: training feature matrices\n",
    "    :param x_test: testing feature matrices\n",
    "    :param y_train: corresponding training labels\n",
    "    :param y_test: corresponding testing labels\n",
    "    :param train_count: distribution by classes in training set\n",
    "    :param test_count: distribution by classes in testing set\n",
    "    :param classes: language to binary correspondence\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    with open(info_data_npy, 'wb') as f:\n",
    "        np.save(f, np.array([train_count, test_count]))\n",
    "        np.save(f, classes)\n",
    "    with open(features_npy, 'wb') as f:\n",
    "        np.save(f, x_train)\n",
    "        np.save(f, y_train)\n",
    "        np.save(f, x_test)\n",
    "        np.save(f, y_test)\n",
    "\n",
    "\n",
    "def open_preprocessed_data():\n",
    "    \"\"\"\n",
    "    Retrieves training and testing sets\n",
    "    and information about classes distribution\n",
    "    saved before from files.\n",
    "    :return: (tuple) training samples, testing samples,\n",
    "    training labels, testing labels,\n",
    "    distribution by classes in training set,\n",
    "    distribution by classes in testing set,\n",
    "    language to binary correspondence\n",
    "    \"\"\"\n",
    "    with open(features_npy, 'rb') as f:\n",
    "        x_train = np.load(f)\n",
    "        y_train = np.load(f)\n",
    "        x_test = np.load(f)\n",
    "        y_test = np.load(f)\n",
    "    with open(info_data_npy, 'rb') as f:\n",
    "        counts = np.load(f, allow_pickle=True)\n",
    "        train_count = counts[0]\n",
    "        test_count = counts[1]\n",
    "        classes = np.load(f, allow_pickle=True).item()\n",
    "    return x_train, x_test, y_train, y_test, train_count, test_count, classes\n",
    "\n",
    "\n",
    "class TerminateOnBaseline(Callback):\n",
    "    \"\"\"\n",
    "    Callback that terminates training when\n",
    "    either accuracy or val_acc reaches\n",
    "    a specified baseline\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, monitor='accuracy', baseline=BASELINE):\n",
    "        super(TerminateOnBaseline, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.baseline = baseline\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        accuracy = logs.get(self.monitor)\n",
    "        if accuracy is not None:\n",
    "            if accuracy >= self.baseline:\n",
    "                logger.debug(f'Epoch {epoch}: Reached baseline, terminating training...')\n",
    "                self.model.stop_training = True\n",
    "\n",
    "\n",
    "class TimeHistory(Callback):\n",
    "    \"\"\"\n",
    "    Callback that saves duration of every training epoch into list.\n",
    "    \"\"\"\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "\n",
    "def compare_sets(x_1, x_2):\n",
    "    \"\"\"\n",
    "    :param x_1: (numpy.ndarray) list of 2-D numpy arrays; training set\n",
    "    :param x_2: (numpy.ndarray) list of 2-D numpy arrays; testing set\n",
    "    :return: String (how many occurrences have been found)\n",
    "    \"\"\"\n",
    "    equal_matrices_num = 0\n",
    "    indices_to_remove = []\n",
    "    for matrix_idx, x_2_matrix in enumerate(x_2):\n",
    "        for x_1_matrix in x_1:\n",
    "            if (x_1_matrix == x_2_matrix).all():\n",
    "                equal_matrices_num += 1\n",
    "                indices_to_remove.append(matrix_idx)\n",
    "                break\n",
    "    return f'Number of equal matrices in sets: {equal_matrices_num}.'\n",
    "\n",
    "\n",
    "def train_model(x_train, y_train, x_validation, y_validation):\n",
    "    \"\"\"\n",
    "    Prepares data for training a 2D CNN model,\n",
    "    builds a model,\n",
    "    performs a model training,\n",
    "    plots accuracy and loss changes during training.\n",
    "    :param x_train: (numpy.ndarray) list of feature matrices for training the network\n",
    "    :param y_train: (numpy.ndarray) list of binary labels training the network\n",
    "    :param x_validation: (numpy.ndarray) list of feature matrices for testing the network\n",
    "    :param y_validation: (numpy.ndarray) list of binary labels testing the network\n",
    "    :return: Trained model\n",
    "    \"\"\"\n",
    "    if CHECK_DATASETS:\n",
    "        logger.debug('Checking whether train and test sets are different...')\n",
    "        logger.debug(f'X train compared with itself. {compare_sets(x_train, x_train)}')\n",
    "        logger.debug(f'X validation compared with itself. {compare_sets(x_validation, x_validation)}')\n",
    "        logger.debug(f'X train compared with x validation. {compare_sets(x_train, x_validation)}')\n",
    "\n",
    "    logger.debug('Getting data dimensions...')\n",
    "\n",
    "    rows = x_train[0].shape[0]\n",
    "    cols = x_train[0].shape[1]\n",
    "    assert x_train[0].shape == x_validation[0].shape\n",
    "    logger.debug('Train and validation matrices are of same dimension...')\n",
    "\n",
    "    train_samples_num = x_train.shape[0]\n",
    "    val_samples_num = x_validation.shape[0]\n",
    "    assert train_samples_num == y_train.shape[0] and val_samples_num == y_validation.shape[0]\n",
    "    logger.debug('X and Y have the same number of samples...')\n",
    "\n",
    "    num_classes = y_train[0].shape[0]\n",
    "\n",
    "    logger.debug(f'Input matrix rows: {rows}')\n",
    "    logger.debug(f'Input matrix columns: {cols}')\n",
    "    logger.debug(f'Num. of classes: {num_classes}')\n",
    "\n",
    "    logger.debug('Reshaping input data...')\n",
    "\n",
    "    input_shape = (rows, cols, 1)\n",
    "    x_train = x_train.reshape(x_train.shape[0], rows, cols, 1)\n",
    "    x_validation = x_validation.reshape(x_validation.shape[0], rows, cols, 1)\n",
    "    logger.debug(f'Input data shape: {input_shape}')\n",
    "\n",
    "    model = build_model(input_shape, num_classes)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    logger.debug(f'Creating a condition for stopping training if accuracy does not change '\n",
    "                 f'at least {MIN_DELTA * 100}% over {PATIENCE} epochs')\n",
    "\n",
    "    es = EarlyStopping(monitor='accuracy', min_delta=MIN_DELTA, patience=PATIENCE, verbose=1, mode='auto',\n",
    "                       restore_best_weights=True)\n",
    "    # es_baseline = TerminateOnBaseline(monitor='accuracy', baseline=BASELINE)\n",
    "    time_history = TimeHistory()\n",
    "\n",
    "    logger.debug('Adding image generator for data augmentation...')\n",
    "    data_generator = ImageDataGenerator(width_shift_range=0.2)\n",
    "\n",
    "    logger.debug('Training model...')\n",
    "    history = model.fit(data_generator.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "                        steps_per_epoch=x_train.shape[0] / BATCH_SIZE, epochs=EPOCHS,\n",
    "                        callbacks=[es, time_history], validation_data=(x_validation, y_validation))\n",
    "    epoch_av_time = round(np.mean(time_history.times), 2)\n",
    "\n",
    "    logger.debug('Model trained.')\n",
    "    logger.info(f'Average epoch time: {epoch_av_time}')\n",
    "    logger.debug('Plotting accuracy and loss...')\n",
    "\n",
    "    plot_history(history)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Builds a 2D CNN model.\n",
    "    :param input_shape: (tuple) shape of input data\n",
    "    to pass to the 1st convolutional layer\n",
    "    :param num_classes: (Int) number of classes for classification\n",
    "    :return: Built Keras 2D CNN model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=KERNEL_SIZE, activation='relu',\n",
    "                     data_format=\"channels_last\",\n",
    "                     input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=POOL_SIZE))\n",
    "    model.add(Conv2D(64, kernel_size=KERNEL_SIZE, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=POOL_SIZE))\n",
    "    model.add(Dropout(DROPOUT))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(DROPOUT))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    \"\"\"\n",
    "    Plots how training and testing\n",
    "    accuracy and loss change\n",
    "    over the training process\n",
    "    :param history: a model's training history\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    fig, ax_loss = plt.subplots(constrained_layout=True)\n",
    "    ax_acc = ax_loss.twinx()\n",
    "\n",
    "    ax_loss.plot(history.history['loss'], label='train loss', color='#E43F04')\n",
    "    ax_loss.plot(history.history['val_loss'], label='test loss', color='#FF9147')\n",
    "\n",
    "    ax_acc.plot(history.history['accuracy'], label='train acc', color='#2201C7')\n",
    "    ax_acc.plot(history.history['val_accuracy'], label='test acc', color='#0055FF')\n",
    "\n",
    "    ax_loss.set_xlabel('epochs')\n",
    "    ax_loss.set_ylabel('loss')\n",
    "    ax_acc.set_ylabel('accuracy')\n",
    "\n",
    "    ax_loss.legend(loc='upper left')\n",
    "    ax_acc.legend(loc='lower left')\n",
    "\n",
    "    plt.title('Model train vs validation')\n",
    "\n",
    "    if USE_COMET_ML:\n",
    "        experiment.log_figure(figure=plt)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def one_hot_to_int(one_hot_arr):\n",
    "    \"\"\"\n",
    "    Convert one-hot encoded data to Int\n",
    "    :param one_hot_arr: list of one-hot encoded numbers\n",
    "    :return: list of numbers represented as integers\n",
    "    \"\"\"\n",
    "    return np.array([np.argmax(one_hot) for one_hot in one_hot_arr])\n",
    "\n",
    "\n",
    "def select_features(x_train, y_train, x_test):\n",
    "    \"\"\"\n",
    "    Performs features selection by flattening\n",
    "    feature matrices\n",
    "    :param x_train: (numpy.ndarray) list of feature matrices used for training\n",
    "    :param y_train: (numpy.ndarray) list of binary labels\n",
    "    :param x_test: (numpy.ndarray) list of features matrices used for testing\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    logger.debug('Performing feature selection...')\n",
    "    logger.debug('[BEFORE SELECTION]')  # matrices won't pass for selection. Choose distinct vectors.\n",
    "    logger.debug(f'X train shape: {x_train.shape}')\n",
    "    logger.debug(f'y train shape: {y_train.shape}')\n",
    "    logger.debug(f'X test shape: {x_test.shape}')\n",
    "\n",
    "    y_train = one_hot_to_int(y_train)\n",
    "\n",
    "    x_train = np.array([x_train.flatten() for x_train in x_train])\n",
    "    x_test = np.array([x_test.flatten() for x_test in x_test])\n",
    "\n",
    "    logger.debug('\\n[AFTER SELECTION]')\n",
    "    logger.debug(f'X train shape: {x_train.shape}')\n",
    "    logger.debug(f'y train shape: {y_train.shape}')\n",
    "    logger.debug(f'X test shape: {x_test.shape}')\n",
    "\n",
    "    if selection_method == 'UNIVARIATE':\n",
    "        selector = SelectKBest(score_func=SCORE_FUNC,\n",
    "                               k=NUM_OF_FEATURES * FRAME_SIZE)  # k = number of features to choose\n",
    "        selector.fit(x_train, y_train)\n",
    "        logger.info(f'Feature selection score: [{selector.scores_}]')\n",
    "    elif selection_method == 'PCE':\n",
    "        selector = PCA(n_components=NUM_OF_FEATURES * FRAME_SIZE)\n",
    "        selector.fit(x_train)\n",
    "        logger.info(f'Explained Variance: {selector.explained_variance_ratio_}')\n",
    "        logger.info(selector.components_)\n",
    "\n",
    "    x_train_selected = selector.transform(x_train)\n",
    "    x_test_selected = selector.transform(x_test)\n",
    "\n",
    "    return x_train_selected, x_test_selected\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Script performing data preparation,\n",
    "    model building and training as well as\n",
    "    model evaluation.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global LANG_SET\n",
    "    global features_npy, info_data_npy\n",
    "\n",
    "    logger.debug('Setting up file paths according to the set up...')\n",
    "\n",
    "    if UNSILENCE:\n",
    "        LANG_SET = LANG_SET + '_unsilenced'\n",
    "    training_languages_str = f'{LANG_SET}_{FRAME_SIZE}'\n",
    "\n",
    "    logger.debug('Creating saving directories if they do not yet exist..')\n",
    "\n",
    "    Path(f'./features/{FEATURES}').mkdir(parents=True, exist_ok=True)\n",
    "    Path(f'./testing_data/{FEATURES}').mkdir(parents=True, exist_ok=True)\n",
    "    Path(f'./models/{FEATURES}').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    logger.debug('Defining saving file names...')\n",
    "\n",
    "    features_npy = f'./features/{FEATURES}/{training_languages_str}.npy'\n",
    "    info_data_npy = f'./testing_data/{FEATURES}/{training_languages_str}.npy'\n",
    "    model_file = f'./models/{FEATURES}/{training_languages_str}.h5'\n",
    "\n",
    "    logger.debug('Getting input data from file in case it has already been retrieved.'\n",
    "                 ' Otherwise preprocessing audios to get this data...')\n",
    "\n",
    "    if not Path.exists(Path(features_npy)) or not Path.exists(Path(info_data_npy)):\n",
    "        df = pd.read_csv(constants.AUDIOS_INFO_FILE_NAME)\n",
    "        df = filter_df(df)\n",
    "        audio_paths = df.path if not UNSILENCE else df.path_unsilenced\n",
    "        corresponding_languages = df.language\n",
    "\n",
    "        preprocess = preprocess_new_data(audio_paths, corresponding_languages)\n",
    "        if not preprocess:\n",
    "            return -1\n",
    "        x_train, x_test, y_train, y_test, train_count, test_count, languages_mapping = preprocess\n",
    "    else:\n",
    "        x_train, x_test, y_train, y_test, train_count, test_count, languages_mapping = open_preprocessed_data()\n",
    "\n",
    "    logger.debug('Selecting features...')\n",
    "\n",
    "    if SELECT_FEATURES:\n",
    "        x_train, x_test = select_features(x_train, y_train, x_test)\n",
    "        x_train, x_test = create_segments_after_selection((x_train, x_test))\n",
    "\n",
    "    if not Path.exists(Path(model_file)):\n",
    "        logger.debug('Training model...')\n",
    "        trained_model = train_model(np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test))\n",
    "        trained_model.summary()\n",
    "        trained_model.save(model_file)\n",
    "    else:\n",
    "        logger.debug('Found trained model. Loading...')\n",
    "        trained_model = load_model(model_file)\n",
    "\n",
    "    languages_classes_mapping = list(languages_mapping.values())\n",
    "\n",
    "    logger.debug('Running model on testing set...')\n",
    "    logger.debug(f'X train shape: {x_train.shape}')\n",
    "    logger.debug(f'X test shape: {x_test.shape}')\n",
    "    logger.debug(f'Y train shape: {y_train.shape}')\n",
    "    logger.debug(f'Y test shape: {y_test.shape}')\n",
    "\n",
    "    y_predicted = np.argmax(trained_model.predict(x_test.reshape(x_test.shape + (1,)), verbose=1), axis=1)\n",
    "    y_test_bool = np.argmax(y_test, axis=1)\n",
    "\n",
    "    logger.info(f'Metrics:\\n{classification_report(y_test_bool, y_predicted, target_names=languages_classes_mapping)}')\n",
    "    logger.debug('Printing statistics (training ans testing counters)...')\n",
    "    logger.info(f'Training samples: {train_count}')\n",
    "    logger.info(f'Testing samples: {test_count}')\n",
    "\n",
    "    if USE_COMET_ML:\n",
    "        logger.debug('Displaying a confusion matrix, overall accuracy...')\n",
    "        cm = ConfusionMatrix()\n",
    "        cm.compute_matrix(y_test, y_predicted)\n",
    "        cm.labels = languages_classes_mapping\n",
    "        confusion_matrix = np.array(cm.to_json()['matrix'])\n",
    "\n",
    "        experiment.log_confusion_matrix(matrix=cm)\n",
    "\n",
    "        logger.debug('Accuracy to beat = (samples of most common class) / (all samples)')\n",
    "        acc_to_beat = np.amax(np.sum(confusion_matrix, axis=1) / np.sum(confusion_matrix))\n",
    "        confusion_matrix_acc = np.sum(confusion_matrix.diagonal()) / float(np.sum(confusion_matrix))\n",
    "        trained_model.evaluate(x_test.reshape(x_test.shape + (1,)), y_test)\n",
    "\n",
    "        logger.info(f'Accuracy to beat: {acc_to_beat}')\n",
    "        logger.info(f'Confusion matrix:\\n {confusion_matrix}')\n",
    "        logger.info(f'Accuracy: {confusion_matrix_acc}')\n",
    "        logger.debug('Displaying the baseline, and whether it has been hit...')\n",
    "\n",
    "        baseline_difference = confusion_matrix_acc - acc_to_beat\n",
    "        if baseline_difference < 0:\n",
    "            logger.info('Baseline has not been hit.')\n",
    "        else:\n",
    "            logger.info(f'Baseline score: {baseline_difference}')\n",
    "    else:  # no Comet ML\n",
    "        trained_model.evaluate(x_test.reshape(x_test.shape + (1,)), y_test, verbose=1)\n",
    "        logger.info(f'Comet ML API_KEY and other variables are not found')\n",
    "        logger.info(f'Confusion Matrix accuracy calculations are not performed')\n",
    "\n",
    "    logger.debug('Showing languages to categorical mapping...')\n",
    "    logger.info(f'Relation classes to categories: {languages_mapping}')\n",
    "\n",
    "    y_predicted_prob = trained_model.predict(x_test.reshape(x_test.shape + (1,)), verbose=1)\n",
    "    logger.info(y_predicted[:10])\n",
    "    logger.info('PROB: ')\n",
    "    logger.info(y_predicted_prob[:10])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51358296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
